{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2912325,"sourceType":"datasetVersion","datasetId":1785111},{"sourceId":7629179,"sourceType":"datasetVersion","datasetId":4444961},{"sourceId":7633171,"sourceType":"datasetVersion","datasetId":4447928},{"sourceId":7640573,"sourceType":"datasetVersion","datasetId":4453021},{"sourceId":7648519,"sourceType":"datasetVersion","datasetId":4458534},{"sourceId":7706252,"sourceType":"datasetVersion","datasetId":4499169},{"sourceId":7738914,"sourceType":"datasetVersion","datasetId":4475507}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom IPython.display import Audio\nfrom sklearn.preprocessing import StandardScaler\nfrom PIL import Image,ImageOps\nfrom io import BytesIO\nimport shutil\nimport seaborn as sns\nimport librosa\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-02-26T22:59:33.518516Z","iopub.execute_input":"2024-02-26T22:59:33.519370Z","iopub.status.idle":"2024-02-26T22:59:48.181643Z","shell.execute_reply.started":"2024-02-26T22:59:33.519334Z","shell.execute_reply":"2024-02-26T22:59:48.180838Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-26 22:59:37.534114: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-26 22:59:37.534239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-26 22:59:37.663440: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **letters**","metadata":{}},{"cell_type":"code","source":"def SpectrogramGenerator(signal,sr,label,audio_name):\n    trimmed_signal, _ = librosa.effects.trim(signal)\n    normalized_audio = librosa.util.normalize(trimmed_signal)\n    duration=int(1*sr)\n    padded_audio = librosa.util.fix_length(trimmed_signal, size=duration)\n    mfcc_feature = librosa.feature.mfcc(y=signal, sr=16000, n_fft=1024,hop_length=30,n_mfcc=13)\n    scaler = StandardScaler()\n    mfcc_feature_standardized = scaler.fit_transform(mfcc_feature)\n    plt.figure(figsize=(1, 1))\n    librosa.display.specshow(librosa.amplitude_to_db(mfcc_feature_standardized,ref=np.max))\n    plt.colorbar(format='%+2.0f dB').remove()\n    buf = BytesIO()\n    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, transparent=True, dpi=100)\n    buf.seek(0)\n    image_name = f\"{audio_name}_spectrogram.png\"\n    image_path = os.path.join(os.path.join(\"/kaggle/working/letters_spectrograms/\",label), image_name)\n    img = Image.open(buf)\n    img = img.resize((200, 200), Image.LANCZOS)\n    img.save(image_path, format='png')\n    plt.close()\n    buf.close() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/letters_spectrograms\", exist_ok=True)\ndata_path = '/kaggle/input/new-audio-arabic-letters/Dataset يارب نخلص'\nlabels = os.listdir(data_path)\nfor label in labels:\n    label_path = os.path.join(data_path, label)\n    os.makedirs(os.path.join(\"/kaggle/working/letters_spectrograms\",label), exist_ok=True)\n    for audio_name in os.listdir(label_path):\n        audio_path = os.path.join(label_path, audio_name)\n        signal,sr=librosa.load(audio_path,sr=16000)\n        y_stretch = librosa.effects.time_stretch(signal, rate=1.2)\n        n_steps = 4\n        y_pitch_shift = librosa.effects.pitch_shift(signal, n_steps=n_steps, sr=sr)\n        noise = np.random.randn(len(signal))\n        y_noise = signal + 0.005 * noise\n        y_speed_up = librosa.effects.time_stretch(signal, rate=1.5)\n        y_slow_down = librosa.effects.time_stretch(signal, rate=0.75)\n        y_reverb = librosa.effects.preemphasis(signal)\n        SpectrogramGenerator(signal,sr,label,audio_name)\n        SpectrogramGenerator(y_stretch,sr,label,audio_name+'_stretch')\n        SpectrogramGenerator(y_pitch_shift,sr,label,audio_name+'_pitch_shift')\n        SpectrogramGenerator(y_noise,sr,label,audio_name+'_noise')\n        SpectrogramGenerator(y_speed_up,sr,label,audio_name+'_speed_up')\n        SpectrogramGenerator(y_slow_down,sr,label,audio_name+'_slow_down')\n        SpectrogramGenerator(y_reverb,sr,label,audio_name+'_reverb')\n        plt.close()\nfor label in labels:\n    label_path = os.path.join(data_path, label)\n    for audio_name in os.listdir(label_path):\n        audio_path = os.path.join(label_path, audio_name)\n        signal,sr=librosa.load(audio_path,sr=16000)\n        y_stretch = librosa.effects.time_stretch(signal, rate=.9)\n        n_steps = 8\n        y_pitch_shift = librosa.effects.pitch_shift(signal, n_steps=n_steps, sr=sr)\n        noise = np.random.randn(len(signal))\n        y_noise = signal + 0.01 * noise\n        y_speed_up = librosa.effects.time_stretch(signal, rate=2)\n        y_slow_down = librosa.effects.time_stretch(signal, rate=0.5)\n        y_reverb = librosa.effects.preemphasis(signal)\n        SpectrogramGenerator(signal,sr,label,audio_name)\n        SpectrogramGenerator(y_stretch,sr,label,audio_name+'_stretch1')\n        SpectrogramGenerator(y_pitch_shift,sr,label,audio_name+'_pitch_shift1')\n        SpectrogramGenerator(y_noise,sr,label,audio_name+'_noise1')\n        SpectrogramGenerator(y_speed_up,sr,label,audio_name+'_speed_up1')\n        SpectrogramGenerator(y_slow_down,sr,label,audio_name+'_slow_down1')\n        SpectrogramGenerator(y_reverb,sr,label,audio_name+'_reverb1')\n        plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/letters_spectrograms', 'zip', '/kaggle/working')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Vowels**","metadata":{}},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/vowels_spectrograms\", exist_ok=True)\ndata_path = '/kaggle/input/arabic-short-vowels-audio-dataset/alphabet_new_dataset'\nlabels = os.listdir(data_path)\nfor label in labels:\n    label_path = os.path.join(data_path, label)\n    os.makedirs(os.path.join(\"/kaggle/working/vowels_spectrograms\",label), exist_ok=True)\n    for audio_name in os.listdir(label_path):\n        audio_path = os.path.join(label_path, audio_name)\n        signal,sr=librosa.load(audio_path,sr=16000)\n        trimmed_signal, _ = librosa.effects.trim(signal)\n        normalized_audio = librosa.util.normalize(trimmed_signal)\n        duration=int(1*sr)\n        padded_audio = librosa.util.fix_length(trimmed_signal, size=duration)\n        mfcc_feature = librosa.feature.mfcc(y=signal, sr=16000, n_mfcc=40)\n        scaler = StandardScaler()\n        mfcc_feature_standardized = scaler.fit_transform(mfcc_feature)\n        plt.figure(figsize=(1, 1))\n        librosa.display.specshow(librosa.amplitude_to_db(mfcc_feature_standardized,ref=np.max))\n        plt.colorbar(format='%+2.0f dB').remove()\n        buf = BytesIO()\n        plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, transparent=True, dpi=100)\n        buf.seek(0)\n        image_name = f\"{audio_name}_spectrogram.png\"\n        image_path = os.path.join(os.path.join(\"/kaggle/working/vowels_spectrograms/\",label), image_name)\n        img = Image.open(buf)\n        img = img.resize((150, 150), Image.LANCZOS)\n        img.save(image_path, format='png')\n        plt.close()\n        buf.close() \nshutil.make_archive('/kaggle/working/vowels_spectrograms', 'zip', '/kaggle/working')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}